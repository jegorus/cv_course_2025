{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Fq7E4y_QS7G"
      },
      "source": [
        "# Семинар 9 - Методы построения оптического потока по последовательности изображений\n",
        "\n",
        "**Этот семинар содержит оцениваемое домашнее задание**\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVfghN5ZQS7N"
      },
      "source": [
        "Источник - https://habr.com/ru/post/201406/\n",
        "\n",
        "$\\textbf{Task statement}$: Оптический поток (ОП) – изображение видимого движения, представляющее собой сдвиг каждой точки (пикселя) между двумя изображениями.\n",
        "\n",
        "По сути, он представляет собой поле скоростей. Суть ОП в том, что для каждой точки изображения $I_{t_0} (\\vec{r})$ находится такой вектор сдвига $\\delta \\vec{r}$, чтобы было соответсвие между исходной точкой и точкой на следущем фрейме $I_{t_1} (\\vec{r} + \\delta \\vec{r})$. В качестве метрики соответвия берут близость интенсивности пикселей, беря во внимание маленькую разницу по времени между кадрами: $\\delta{t} = t_{1} - t_{0}$. В более точных методах точку можно привязывать к объекту на основе, например, выделения ключевых точек, а также считать градиенты вокруг точки, лапласианы и проч.\n",
        "\n",
        "$\\textbf{For what}$: Определение собственной скорости, Определение локализации, Улучшение методов трекинга объектов, сегментации, Детектирование событий, Сжатие видеопотока и проч.\n",
        "\n",
        "![](data/tennis.png)\n",
        "\n",
        "Разделяют 2 вида оптического потока - плотный (dense) [Farneback method, neural nets], работающий с целым изображением, и выборочный (sparse) [Lucas-Kanade method], работающий с ключевыми точками"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/alexmelekhin/cv_course_2025.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsqNN090fTam",
        "outputId": "bfb7b8c6-d9ae-4705-ee01-368d37904ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cv_course_2025'...\n",
            "remote: Enumerating objects: 158, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 158 (delta 10), reused 9 (delta 9), pack-reused 137 (from 3)\u001b[K\n",
            "Receiving objects: 100% (158/158), 53.04 MiB | 22.85 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r cv_course_2025/seminars/seminar_09/data ."
      ],
      "metadata": {
        "id": "khc4yPegfhy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_suJZ5AQS7P",
        "outputId": "2c67fd5d-1d39-4582-fb39-e5dfaaf18981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-14 08:51:31--  https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4\n",
            "Resolving www.bogotobogo.com (www.bogotobogo.com)... 173.254.30.214\n",
            "Connecting to www.bogotobogo.com (www.bogotobogo.com)|173.254.30.214|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2018126 (1.9M) [video/mp4]\n",
            "Saving to: ‘data/slow_traffic_small.mp4’\n",
            "\n",
            "data/slow_traffic_s 100%[===================>]   1.92M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-04-14 08:51:31 (16.2 MB/s) - ‘data/slow_traffic_small.mp4’ saved [2018126/2018126]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4 -O data/slow_traffic_small.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvyURLwHQS7S"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J05ayu1QS7T"
      },
      "source": [
        "## Lucas-Kanade (sparse)\n",
        "\n",
        "Пусть $I_{1} = I(x, y, t_{1})$ интенсивность в некоторой точке (x, y) на первом изображении (т. е. в момент времени t). На втором изображении эта точка сдвинулась на (dx, dy), при этом прошло время dt, тогда $I_{2} = I(x + dx, y + dx, t_{1} + dt) \\approx I_{1} + I_{x}dx + I_{y}dy +  I_{t}dt$. Из постановки задачи следует, что интенсивность пикселя не изменилась, тогда $I_{1} = I_{2}$. Далее определяем $dx, dy$.\n",
        "\n",
        "Самое простое решение проблемы – алгоритм Лукаса-Канаде. У нас же на изображении объекты размером больше 1 пикселя, значит, скорее всего, в окрестности текущей точки у других точек будут примерно такие же сдвиги. Поэтому мы возьмем окно вокруг этой точки и минимизируем (по МНК) в нем суммарную погрешность с весовыми коэффициентами, распределенными по Гауссу, то есть так, чтобы наибольший вес имели пиксели, ближе всего находящиеся к исследуемому.\n",
        "\n",
        "**Полезные материалы:**\n",
        "- цикл видео-лекций от First Principles of Computer Vision, посвященный Optical Flow и алгоритму Lucas-Kanade: https://youtube.com/playlist?list=PL2zRqk16wsdoYzrWStffqBAoUY8XdvatV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSFPsO2uQS7V"
      },
      "source": [
        "### Вопрос 1\n",
        "\n",
        "Перечислите три основных предположения, на которых базируется метод Lucas-Kanade. Почему каждое из них важно для корректной работы алгоритма?\n",
        "\n",
        "**Ответ:**\n",
        "1. $I_1 = I_2$ - интенсивность не изменяется\n",
        "2. Сдвиг точек небольшой. Это важно, т. к. в алгоритме применяется разложение по Тейлору\n",
        "3. Движение однородно в локальной области\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYllrXWzQS7W"
      },
      "source": [
        "### Вопрос 2\n",
        "\n",
        "Объясните, зачем нужен пирамидальный подход в алгоритме Lucas-Kanade. Какую проблему он решает и как именно?\n",
        "\n",
        "**Ответ:** решает проблему малого перемещения с помощью использования нескольких уровней с последовательным уточнением"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyHSWGOEQS7X"
      },
      "source": [
        "### Вопрос 3\n",
        "\n",
        "С какими проблемами может столкнуться алгоритм Lucas-Kanade при отслеживании точек на видео? Назовите минимум три ограничения.\n",
        "\n",
        "**Ответ:** Ограничения возникают из-за предположений:\n",
        "1. Интенсивность изменилась (блик)\n",
        "2. Большой сдвиг (резкий поворот камеры)\n",
        "3. Неоднородное движение (два объекта пересекаются)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0-i81VUQS7Y"
      },
      "source": [
        "### Задание 1\n",
        "\n",
        "Напишите реализацию Лукаса-Канаде c помощью numpy и cv2. Сравните с реализацией `cv2.calcOpticalFlowPyrLK`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nBtuDH99QS7Z"
      },
      "outputs": [],
      "source": [
        "def build_image_pyramid(image, num_levels, scale_factor=0.5):\n",
        "    \"\"\"\n",
        "    Создаёт пирамиду изображений с уменьшающимся разрешением.\n",
        "\n",
        "    Аргументы:\n",
        "        image: Исходное изображение (одноканальное, grayscale)\n",
        "        num_levels: Количество уровней пирамиды\n",
        "        scale_factor: Коэффициент масштабирования между соседними уровнями\n",
        "\n",
        "    Возвращает:\n",
        "        Список изображений [image_level_0, image_level_1, ..., image_level_n-1], где:\n",
        "        - image_level_0 - исходное изображение\n",
        "        - Каждый следующий уровень уменьшен относительно предыдущего в scale_factor раз\n",
        "\n",
        "    Примечание:\n",
        "        - Используйте cv2.resize с интерполяцией cv2.INTER_LINEAR для уменьшения размера\n",
        "        - Первым элементом списка должна быть копия исходного изображения\n",
        "    \"\"\"\n",
        "    images = [image.copy()]\n",
        "    for i in range(num_levels - 1):\n",
        "        h = int(images[-1].shape[0] * scale_factor)\n",
        "        w = int(images[-1].shape[1] * scale_factor)\n",
        "        images.append(cv2.resize(images[-1], (w, h), interpolation=cv2.INTER_LINEAR))\n",
        "    return images\n",
        "\n",
        "\n",
        "def compute_image_gradients(image):\n",
        "    \"\"\"\n",
        "    Вычисляет пространственные градиенты изображения.\n",
        "\n",
        "    Аргументы:\n",
        "        image: Входное изображение (одноканальное, grayscale)\n",
        "\n",
        "    Возвращает:\n",
        "        Кортеж (Ix, Iy), где Ix и Iy - градиенты по x и y соответственно\n",
        "\n",
        "    Примечание:\n",
        "        - Используйте фильтр Собеля (cv2.Sobel) с ksize=3\n",
        "        - Используйте тип данных cv2.CV_64F для более точных вычислений\n",
        "    \"\"\"\n",
        "    Ix = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
        "    Iy = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
        "\n",
        "    return Ix, Iy\n",
        "\n",
        "\n",
        "def compute_lk_optical_flow_point(Ix, Iy, It, window_size=5):\n",
        "    \"\"\"\n",
        "    Вычисляет оптический поток по методу Lucas-Kanade для одного окна.\n",
        "\n",
        "    Аргументы:\n",
        "        Ix: Градиент изображения по x\n",
        "        Iy: Градиент изображения по y\n",
        "        It: Временной градиент (разница между кадрами)\n",
        "        window_size: Размер окна для вычисления (нечетное число)\n",
        "\n",
        "    Возвращает:\n",
        "        Кортеж (u, v) компонентов вектора потока или (None, None) если решение ненадежное\n",
        "\n",
        "    Примечание:\n",
        "        - Создайте окно для градиентов, выбрав центральный пиксель и окно размером window_size x window_size\n",
        "        - Вычислите сумму произведений градиентов для формирования матрицы A:\n",
        "          A = [[sum(Ix*Ix), sum(Ix*Iy)], [sum(Ix*Iy), sum(Iy*Iy)]]\n",
        "        - Проверьте обусловленность матрицы A через собственные значения\n",
        "        - Если минимальное собственное значение меньше порога (например, 1e-4), верните (None, None)\n",
        "        - Сформируйте вектор b: [-sum(Ix*It), -sum(Iy*It)]\n",
        "        - Решите систему уравнений A * [u, v] = b\n",
        "        - Обработайте возможное исключение np.linalg.LinAlgError\n",
        "    \"\"\"\n",
        "\n",
        "    half_win = window_size // 2\n",
        "\n",
        "    center_y = Ix.shape[0] // 2\n",
        "    center_x = Ix.shape[1] // 2\n",
        "\n",
        "    Ix_win = Ix[center_y - half_win:center_y + half_win + 1, center_x - half_win:center_x + half_win + 1].flatten()\n",
        "    Iy_win = Iy[center_y - half_win:center_y + half_win + 1, center_x - half_win:center_x + half_win + 1].flatten()\n",
        "    It_win = It[center_y - half_win:center_y + half_win + 1, center_x - half_win:center_x + half_win + 1].flatten()\n",
        "\n",
        "    A = np.vstack((Ix_win, Iy_win)).T\n",
        "    ATA = A.T @ A\n",
        "    eigenvals = np.linalg.eigvals(ATA)\n",
        "    if np.min(eigenvals) < 1e-4:\n",
        "        return None, None\n",
        "\n",
        "    b = -It_win\n",
        "    try:\n",
        "        sol = np.linalg.inv(ATA) @ (A.T @ b)\n",
        "        return sol[0], sol[1]\n",
        "\n",
        "\n",
        "    except np.linalg.LinAlgError:\n",
        "        return None, None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def compute_lk_optical_flow_for_patch(prev_patch, curr_patch, window_size=5):\n",
        "    \"\"\"\n",
        "    Вычисляет оптический поток для патча изображения.\n",
        "\n",
        "    Аргументы:\n",
        "        prev_patch: Патч из предыдущего кадра\n",
        "        curr_patch: Соответствующий патч из текущего кадра\n",
        "        window_size: Размер окна для LK\n",
        "\n",
        "    Возвращает:\n",
        "        Кортеж (u, v) компонентов вектора потока для центра патча\n",
        "\n",
        "    Примечание:\n",
        "        - Вычислите пространственные градиенты prev_patch с помощью compute_image_gradients\n",
        "        - Вычислите временной градиент как разность патчей: It = curr_patch - prev_patch\n",
        "        - Используйте функцию compute_lk_optical_flow_point для вычисления вектора потока\n",
        "    \"\"\"\n",
        "    Ix, Iy = compute_image_gradients(prev_patch)\n",
        "    It = curr_patch - prev_patch\n",
        "    return compute_lk_optical_flow_point(Ix, Iy, It, window_size)\n",
        "\n",
        "\n",
        "def track_point_with_pyramid_lk(prev_pyramid, curr_pyramid, point, window_size=15, max_iterations=10, epsilon=0.01):\n",
        "    \"\"\"\n",
        "    Отслеживает точку между кадрами с использованием пирамидального LK.\n",
        "\n",
        "    Аргументы:\n",
        "        prev_pyramid: Пирамида предыдущего кадра (список изображений)\n",
        "        curr_pyramid: Пирамида текущего кадра (список изображений)\n",
        "        point: Координаты отслеживаемой точки (x, y) на исходном изображении\n",
        "        window_size: Размер окна для LK\n",
        "        max_iterations: Максимальное количество итераций для уточнения каждого уровня\n",
        "        epsilon: Порог для остановки итераций\n",
        "\n",
        "    Возвращает:\n",
        "        Кортеж (new_x, new_y) - новые координаты точки на текущем кадре\n",
        "        или None если отслеживание неуспешно\n",
        "\n",
        "    Примечание:\n",
        "        - Начните обработку с верхнего уровня пирамиды (самое маленькое изображение)\n",
        "        - Масштабируйте исходную точку для соответствия размеру изображения верхнего уровня\n",
        "        - Для каждого уровня пирамиды (от верхнего к нижнему):\n",
        "            1. Масштабируйте общее смещение в 2 раза при переходе на уровень ниже\n",
        "            2. Пересчитайте позицию точки с учетом масштаба текущего уровня\n",
        "            3. Примените итеративное уточнение позиции с помощью LK:\n",
        "                a. Проверьте, что точка и окно вокруг неё находятся в границах изображения\n",
        "                b. Извлеките патчи из предыдущего и текущего кадров\n",
        "                c. Вычислите смещение с помощью compute_lk_optical_flow_for_patch\n",
        "                d. Обновите позицию точки\n",
        "                e. Остановите итерации, если смещение меньше epsilon\n",
        "            4. Обновите общее смещение\n",
        "        - Вычислите финальную позицию точки на исходном изображении\n",
        "    \"\"\"\n",
        "\n",
        "    shift_x = 0\n",
        "    shift_y = 0\n",
        "\n",
        "    for lvl in reversed(range(len(prev_pyramid))):\n",
        "        prev_img = prev_pyramid[lvl]\n",
        "        curr_img = curr_pyramid[lvl]\n",
        "\n",
        "        scale = 0.5 ** lvl\n",
        "        scaled_point_x = point[0] * scale + shift_x\n",
        "        scaled_point_y = point[1] * scale + shift_y\n",
        "\n",
        "        for i in range(max_iterations):\n",
        "            scaled_x_int = int(scaled_point_x)\n",
        "            scaled_y_int = int(scaled_point_y)\n",
        "\n",
        "            half_win = window_size // 2\n",
        "\n",
        "            if scaled_x_int - half_win < 0 or scaled_x_int + half_win + 1 > prev_img.shape[1] or scaled_y_int - half_win < 0 or scaled_y_int + half_win + 1 > prev_img.shape[0]:\n",
        "                return None\n",
        "\n",
        "            prev_patch = prev_img[scaled_y_int - half_win:scaled_y_int + half_win + 1, scaled_x_int - half_win:scaled_x_int + half_win + 1]\n",
        "            curr_patch = curr_img[scaled_y_int - half_win:scaled_y_int + half_win + 1, scaled_x_int - half_win:scaled_x_int + half_win + 1]\n",
        "\n",
        "            u, v = compute_lk_optical_flow_for_patch(prev_patch, curr_patch, window_size)\n",
        "\n",
        "            if u is None or v is None:\n",
        "                return None\n",
        "\n",
        "            scaled_point_x += u\n",
        "            scaled_point_y += v\n",
        "\n",
        "            if np.sqrt(u ** 2 + v ** 2) < epsilon:\n",
        "                break\n",
        "\n",
        "        shift_x = (scaled_point_x - point[0] * scale) * 2\n",
        "        shift_y = (scaled_point_y - point[1] * scale) * 2\n",
        "\n",
        "    return point[0] + shift_x, point[1] + shift_y\n",
        "\n",
        "\n",
        "\n",
        "def lucas_kanade_optical_flow(prev_frame, curr_frame, points,\n",
        "                             window_size=15, num_pyramid_levels=3,\n",
        "                             max_iterations=10, epsilon=0.01):\n",
        "    \"\"\"\n",
        "    Вычисляет разреженный оптический поток методом Лукаса-Канаде.\n",
        "\n",
        "    Аргументы:\n",
        "        prev_frame: Предыдущий кадр (может быть цветным)\n",
        "        curr_frame: Текущий кадр (может быть цветным)\n",
        "        points: Список точек для отслеживания в формате [[x1, y1], [x2, y2], ...]\n",
        "        window_size: Размер окна для LK\n",
        "        num_pyramid_levels: Количество уровней в пирамиде изображений\n",
        "        max_iterations: Максимальное количество итераций на каждом уровне\n",
        "        epsilon: Порог сходимости для итераций\n",
        "\n",
        "    Возвращает:\n",
        "        Кортеж (new_points, status), где:\n",
        "        - new_points: Массив новых позиций точек в формате [[x1, y1], [x2, y2], ...]\n",
        "        - status: Массив статусов отслеживания (1 - успешно, 0 - неуспешно)\n",
        "\n",
        "    Примечание:\n",
        "        - Преобразуйте входные кадры в полутоновые, если они цветные\n",
        "        - Нормализуйте изображения к диапазону [0, 1]\n",
        "        - Создайте пирамиды изображений для обоих кадров\n",
        "        - Для каждой точки из списка:\n",
        "            1. Отследите её с помощью track_point_with_pyramid_lk\n",
        "            2. Сохраните результат в new_points и отметьте статус в status\n",
        "        - Если отслеживание точки не удалось, установите статус 0 и сохраните исходную точку\n",
        "    \"\"\"\n",
        "    prev_frame_gray = prev_frame.copy()\n",
        "    curr_frame_gray = curr_frame.copy()\n",
        "    if len(prev_frame.shape) == 3:\n",
        "        prev_frame_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
        "    if len(curr_frame.shape) == 3:\n",
        "        curr_frame_gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    prev_frame_gray = prev_frame_gray.astype(np.float32)\n",
        "    curr_frame_gray = curr_frame_gray.astype(np.float32)\n",
        "\n",
        "    prev_frame_gray /= 255.0\n",
        "    curr_frame_gray /= 255.0\n",
        "\n",
        "    prev_img_pyramid = build_image_pyramid(prev_frame_gray, num_pyramid_levels)\n",
        "    curr_img_pyramid = build_image_pyramid(curr_frame_gray, num_pyramid_levels)\n",
        "\n",
        "    new_points = []\n",
        "    status = []\n",
        "\n",
        "    for point in points:\n",
        "        tracked_point = track_point_with_pyramid_lk(prev_img_pyramid, curr_img_pyramid, point, window_size, max_iterations, epsilon)\n",
        "\n",
        "        if tracked_point is not None:\n",
        "            new_points.append(tracked_point)\n",
        "            status.append(1)\n",
        "        else:\n",
        "            new_points.append(point)\n",
        "            status.append(0)\n",
        "\n",
        "    return np.array(new_points), np.array(status)\n",
        "\n",
        "\n",
        "def demo_optical_flow(video_path='data/slow_traffic_small.mp4', output_path='output_my_LK.mp4'):\n",
        "    \"\"\"\n",
        "    Демонстрация работы алгоритма на видео.\n",
        "\n",
        "    Args:\n",
        "        video_path: Путь к входному видео\n",
        "        output_path: Путь для сохранения результата\n",
        "    \"\"\"\n",
        "    # Открываем видео\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Получаем параметры видео\n",
        "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Настраиваем запись выходного видео\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Параметры для обнаружения углов Shi-Tomasi\n",
        "    feature_params = dict(\n",
        "        maxCorners=100,\n",
        "        qualityLevel=0.3,\n",
        "        minDistance=7,\n",
        "        blockSize=7\n",
        "    )\n",
        "\n",
        "    # Берем первый кадр и находим в нем углы\n",
        "    ret, old_frame = cap.read()\n",
        "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "    p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
        "    p0 = p0.reshape(-1, 2)  # Преобразуем в формат [[x1, y1], [x2, y2], ...]\n",
        "\n",
        "    # Сохраняем изначальные точки для отслеживания через все видео\n",
        "    initial_points = p0.copy()\n",
        "\n",
        "    # Создаем маску для рисования\n",
        "    mask = np.zeros_like(old_frame)\n",
        "\n",
        "    # Создаем случайные цвета для визуализации\n",
        "    color = np.random.randint(0, 255, (len(p0), 3))\n",
        "\n",
        "    from tqdm import tqdm\n",
        "    for i in tqdm(range(length - 1)):  # -1 потому что первый кадр мы уже прочитали\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            print('No frames grabbed!')\n",
        "            break\n",
        "\n",
        "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Вычисляем оптический поток с помощью нашей реализации\n",
        "        p1, st = lucas_kanade_optical_flow(\n",
        "            old_gray,\n",
        "            frame_gray,\n",
        "            p0,\n",
        "            window_size=15,\n",
        "            num_pyramid_levels=3\n",
        "        )\n",
        "\n",
        "        # Выбираем хорошие точки\n",
        "        good_new = p1[st == 1]\n",
        "        good_old = p0[st == 1]\n",
        "\n",
        "        # Рисуем треки\n",
        "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
        "            a, b = new\n",
        "            c, d = old\n",
        "            mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[i % len(color)].tolist(), 2)\n",
        "            frame = cv2.circle(frame, (int(a), int(b)), 5, color[i % len(color)].tolist(), -1)\n",
        "\n",
        "        # Объединяем кадр и маску\n",
        "        img = cv2.add(frame, mask)\n",
        "\n",
        "        # Записываем результат\n",
        "        out.write(img)\n",
        "\n",
        "        # Обновляем предыдущий кадр\n",
        "        old_gray = frame_gray.copy()\n",
        "\n",
        "        # Обновляем точки, но только те, которые успешно отслежены\n",
        "        p0[st == 1] = good_new\n",
        "\n",
        "    # Освобождаем ресурсы\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    print(f\"Результат сохранен в {output_path}\")\n",
        "    return output_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "02BN2WyEQS7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f25b483-6325-4972-9101-54ec3bebddfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 913/913 [00:15<00:00, 57.61it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат сохранен в output_my_LK.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "result_path = demo_optical_flow(video_path='data/slow_traffic_small.mp4', output_path='output_my_LK.mp4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xne5iHOZQS7f"
      },
      "source": [
        "### Релизация OpenCV - cv2.calcOpticalFlowPyrLK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "h0jThyHtQS7g"
      },
      "outputs": [],
      "source": [
        "def demo_optical_flow_opencv(video_path='data/slow_traffic_small.mp4', output_path='output_my_LK.mp4'):\n",
        "    \"\"\"\n",
        "    Демонстрация работы алгоритма на видео с использованием cv2.calcOpticalFlowPyrLK.\n",
        "\n",
        "    Args:\n",
        "        video_path: Путь к входному видео\n",
        "        output_path: Путь для сохранения результата\n",
        "    \"\"\"\n",
        "    # Открываем видео\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Получаем параметры видео\n",
        "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Настраиваем запись выходного видео\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Параметры для обнаружения углов Shi-Tomasi\n",
        "    feature_params = dict(\n",
        "        maxCorners=100,\n",
        "        qualityLevel=0.3,\n",
        "        minDistance=7,\n",
        "        blockSize=7\n",
        "    )\n",
        "\n",
        "    # Параметры для Lucas-Kanade оптического потока\n",
        "    lk_params = dict(\n",
        "        winSize=(15, 15),\n",
        "        maxLevel=3,\n",
        "        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
        "    )\n",
        "\n",
        "    # Берем первый кадр и находим в нем углы\n",
        "    ret, old_frame = cap.read()\n",
        "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "    p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
        "\n",
        "    # Создаем маску для рисования\n",
        "    mask = np.zeros_like(old_frame)\n",
        "\n",
        "    # Создаем случайные цвета для визуализации\n",
        "    color = np.random.randint(0, 255, (100, 3))\n",
        "\n",
        "    from tqdm import tqdm\n",
        "    for i in tqdm(range(length - 1)):  # -1 потому что первый кадр мы уже прочитали\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            print('No frames grabbed!')\n",
        "            break\n",
        "\n",
        "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Вычисляем оптический поток с помощью встроенной функции cv2.calcOpticalFlowPyrLK\n",
        "        p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
        "\n",
        "        # Выбираем хорошие точки\n",
        "        if p1 is not None:\n",
        "            good_new = p1[st == 1]\n",
        "            good_old = p0[st == 1]\n",
        "\n",
        "        # Рисуем треки\n",
        "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
        "            a, b = new.ravel()\n",
        "            c, d = old.ravel()\n",
        "            mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[i % len(color)].tolist(), 2)\n",
        "            frame = cv2.circle(frame, (int(a), int(b)), 5, color[i % len(color)].tolist(), -1)\n",
        "\n",
        "        # Объединяем кадр и маску\n",
        "        img = cv2.add(frame, mask)\n",
        "\n",
        "        # Записываем результат\n",
        "        out.write(img)\n",
        "\n",
        "        # Обновляем предыдущий кадр\n",
        "        old_gray = frame_gray.copy()\n",
        "\n",
        "        # Обновляем точки, но только те, которые успешно отслежены\n",
        "        p0 = good_new.reshape(-1, 1, 2)\n",
        "\n",
        "    # Освобождаем ресурсы\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    print(f\"Результат сохранен в {output_path}\")\n",
        "    return output_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "N7FOhoHmQS7h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6de0ad3-1023-4ae5-d12b-098dda58cccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 913/913 [00:02<00:00, 355.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат сохранен в output_opencv_LK.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "result_path = demo_optical_flow_opencv(video_path='data/slow_traffic_small.mp4', output_path='output_opencv_LK.mp4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0flo3qlQS7i"
      },
      "source": [
        "### Задание 2\n",
        "\n",
        "В базовой реализации у кода есть одна важная проблема - ключевые точки инициализируются единожды. В реальных задачах необходимо отслеживать точки, которые исчезают из кадра и появляются в других местах. Реализуйте механизм, который будет отслеживать точки, которые пропадают из кадра и добавлять новые точки в те места, где они появляются. Для этого вам нужно будет реализовать механизм поиска новых точек на изображении."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrmZAo9rQS7k"
      },
      "source": [
        "### Вопрос 4\n",
        "\n",
        "В чем основное отличие разреженного (sparse) оптического потока Lucas-Kanade от плотного (dense) оптического потока (например, метода Farneback)?\n",
        "\n",
        "**Ответ:** sparse - оценивает для отдельных точек \\\n",
        "dense - для всего изображения (для каждого пикселя)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI9N7SeVQS7k"
      },
      "source": [
        "## Farneback (dense)\n",
        "\n",
        "Метод Farneback носит несколько более глобальный характер, чем метод Лукаса-Канаде. Он опирается на предположение о том, что на всем изображении оптический поток будет достаточно гладким."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPBJaTNNQS7l"
      },
      "source": [
        "# Вопрос 5\n",
        "\n",
        "Перечислите основные шаги алгоритма Farneback для расчета оптического потока.\n",
        "\n",
        "**Ответ:**\n",
        "1. Аппроксимация окна с помощью полиномиальных функций\n",
        "2. Построение пирамиды Гаусса\n",
        "3. Оценка движения на грубом уровне\n",
        "4. Итеративное уточнение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-iBa6aLQS7m"
      },
      "source": [
        "### Вопрос 6\n",
        "\n",
        "Каким образом в методе Farneback обрабатываются большие смещения объектов между кадрами?\n",
        "\n",
        "**Ответ:** с помощью гауссовой пирамиды, обработка на маленьком изображении\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "U2w-YcX1QS7m"
      },
      "outputs": [],
      "source": [
        "def demo_optical_flow_farneback_opencv(video_path='data/slow_traffic_small.mp4', output_path='output_Farneback.mp4'):\n",
        "    \"\"\"\n",
        "    Демонстрация работы алгоритма плотного оптического потока Farneback на видео.\n",
        "\n",
        "    Args:\n",
        "        video_path: Путь к входному видео\n",
        "        output_path: Путь для сохранения результата\n",
        "    \"\"\"\n",
        "    # Открываем видео\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Получаем параметры видео\n",
        "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Настраиваем запись выходного видео\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Берем первый кадр и преобразуем его в оттенки серого\n",
        "    ret, frame1 = cap.read()\n",
        "    if not ret:\n",
        "        print('Не удалось прочитать видео')\n",
        "        return None\n",
        "\n",
        "    prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Создаем HSV-изображение для визуализации потока\n",
        "    hsv = np.zeros_like(frame1)\n",
        "    hsv[..., 1] = 255  # Насыщенность устанавливаем на максимум\n",
        "\n",
        "    from tqdm import tqdm\n",
        "    for i in tqdm(range(length - 1)):  # -1 потому что первый кадр мы уже прочитали\n",
        "        ret, frame2 = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            print('No frames grabbed!')\n",
        "            break\n",
        "\n",
        "        next_frame = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Вычисляем оптический поток методом Farneback\n",
        "        # Параметры:\n",
        "        # - 0.5: коэффициент масштабирования для пирамиды изображений\n",
        "        # - 3: кол-во уровней пирамиды\n",
        "        # - 15: размер окна для усреднения\n",
        "        # - 3: число итераций на каждом уровне пирамиды\n",
        "        # - 5: размер окна для полиномиальной аппроксимации\n",
        "        # - 1.2: стандартное отклонение для сглаживания\n",
        "        flow = cv2.calcOpticalFlowFarneback(\n",
        "            prvs, next_frame, None,\n",
        "            0.5, 3, 15, 3, 5, 1.2, 0\n",
        "        )\n",
        "\n",
        "        # Преобразуем векторы потока из декартовых координат в полярные\n",
        "        mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "\n",
        "        # Кодируем направление потока как оттенок (hue)\n",
        "        hsv[..., 0] = ang * 180 / np.pi / 2\n",
        "\n",
        "        # Кодируем величину потока как яркость (value)\n",
        "        hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
        "\n",
        "        # Преобразуем HSV в BGR для отображения\n",
        "        bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "        # Записываем результат\n",
        "        out.write(bgr)\n",
        "\n",
        "        # Обновляем предыдущий кадр\n",
        "        prvs = next_frame\n",
        "\n",
        "    # Освобождаем ресурсы\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    print(f\"Результат сохранен в {output_path}\")\n",
        "    return output_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "pk8CBFKaQS7o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88a9a69a-b11d-49de-f4c6-fa3e0c725c5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 913/913 [00:55<00:00, 16.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат сохранен в output_opencv_farneback.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "result_path = demo_optical_flow_farneback_opencv(video_path='data/slow_traffic_small.mp4', output_path='output_opencv_farneback.mp4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNiVObKbQS7o"
      },
      "source": [
        "### Вопрос 7\n",
        "\n",
        "Как влияет предварительная обработка изображений (фильтрация шума, выравнивание гистограмм) на качество оптического потока, получаемого методом Farneback? Предложите оптимальный пайплайн предобработки.\n",
        "\n",
        "**Ответ:** Farneback чувствителен к шуму и яркости, поэтому стоит нормализовать \\\n",
        "Пайплайн: BGR2GRAY, GaussianBlur, equalizeHist, createCLAHE (для яркости/освещения)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cv_course",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}